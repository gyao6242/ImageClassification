{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc73d7dc-e456-4802-8a55-2e5d8c7491df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Enum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m montage\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32mE:\\python\\Lib\\site-packages\\fastai\\basic_data.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_collate\n\u001b[1;32m----> 5\u001b[0m DatasetType \u001b[38;5;241m=\u001b[39m \u001b[43mEnum\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasetType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Valid Test Single Fix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataBunch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeviceDataLoader\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasetType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m old_dl_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Enum' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import * # TODO: Use DataBlock API and DataLoader classes, fastai.basic_data has been deprecated\n",
    "from skimage.util import montage\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import albumentations\n",
    "from fastai.callbacks.hooks import num_features_model\n",
    "from torch.nn import L1Loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229f23b4-cb3b-4aef-b75b-015552b48c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "\n",
    "# Compute the Average Precision with a maximum number of predicted elements\n",
    "# -actual, predicted : lists of items\n",
    "# - k : int number of maximum predicted elements (default value is 10)\n",
    "def apk(actualList, predictedList, k=10):\n",
    "    # If the actualList is empty, return 0.0 since the precision cannot be computed\n",
    "    if not actualList: \n",
    "        return 0.0\n",
    "    # If the length of the predicted list is greater than k, slice the predicted list such that it only keeps the first 'k' elements\n",
    "    if len(predictedList) > k:\n",
    "        predictedList = predictedList[:k]\n",
    "      \n",
    "    score = 0.0 # Determines the precision\n",
    "    num_hits = 0.0 # Tracks the number of correct predictions\n",
    "    \n",
    "    # Loop over each index and element in predicted\n",
    "    for i,p in enumerate(predictedList):\n",
    "        # Check if the element is within actualList and is not a duplicate from previous iterations\n",
    "        if p in actualList and p not in predictedList[:i]:\n",
    "            num_hits += 1\n",
    "            score += num_hits / (i + 1) # Rewards early correct predictions, and penalizes later correct predictions\n",
    "        \n",
    "    return score / min(len(actualList), k) \n",
    "\n",
    "# Averages the APK score from a list of actualLists and predictedLists\n",
    "def mapk(actualList, predictedList, k=10):\n",
    "    # zip() pairs elements from two iterables.\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actualList,predictedList)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad96ec8-5a18-4c7e-9ea5-5a5ffcde8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map5kfast(preds, targs, k=10):\n",
    "    predicted_idxs = preds.sort(descending=True)[1]\n",
    "    top_5 = predicted_idxs[:, :5]\n",
    "    scores = torch.zeros(len(preds), k).float()\n",
    "    for kk in range(k):\n",
    "        scores[:,kk] = (top_5[:,kk] == targs).float() / float((kk+1))\n",
    "    return scores.max(dim=1)[0].mean()\n",
    "\n",
    "def map5(preds,targs):\n",
    "    if type(preds) is list:\n",
    "        return torch.cat([map5fast(p, targs, 5).view(1) for p in preds ]).mean()\n",
    "    return map5kfast(preds,targs, 5)\n",
    "\n",
    "def top_5_preds(preds): return np.argsort(preds.numpy())[:, ::-1][:, :5]\n",
    "\n",
    "def top_5_pred_labels(preds, classes):\n",
    "    top_5 = top_5_preds(preds)\n",
    "    labels = []\n",
    "    for i in range(top_5.shape[0]):\n",
    "        labels.append(' '.join([classes[idx] for idx in top_5[i]]))\n",
    "    return labels\n",
    "\n",
    "def create_submission(preds, data, name, classes=None):\n",
    "    if not classes: classes = data.classes\n",
    "    sub = pd.DataFrame({'Image': [path.name for path in data.test_ds.x.items]})\n",
    "    sub['Id'] = top_5_pred_labels(preds, classes)\n",
    "    sub.to_csv(f'subs/{name}.csv.gz', index=False, compression='gzip')\n",
    "\n",
    "\n",
    "def intersection(preds, targs):\n",
    "    # preds and targs are of shape (bs, 4), pascal_voc format\n",
    "    max_xy = torch.min(preds[:, 2:], targs[:, 2:])\n",
    "    min_xy = torch.max(preds[:, :2], targs[:, :2])\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
    "    return inter[:, 0] * inter[:, 1]\n",
    "\n",
    "def area(boxes):\n",
    "    return ((boxes[:, 2]-boxes[:, 0]) * (boxes[:, 3]-boxes[:, 1]))\n",
    "\n",
    "def union(preds, targs):\n",
    "    return area(preds) + area(targs) - intersection(preds, targs)\n",
    "\n",
    "def IoU(preds, targs):\n",
    "    return intersection(preds, targs) / union(preds, targs)\n",
    "\n",
    "def name(n=10, print_it=True):\n",
    "    name = \"\".join(random.choice(string.ascii_lowercase) for _ in range(n))\n",
    "    if print_it: print(name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecef054-d78f-4e1b-958b-5c854078663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json.load(open('TODO: import data here'))\n",
    "len(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f0a87-1c6f-4e85-874a-a1e8da024137",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,temp in enumerate(j):\n",
    "    test=temp['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160be0b-d4ab-41ad-94f3-7fbd5ba5e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastprogress import force_console_behavior\n",
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9168eb1-fe6f-4ee1-89db-e199e0683016",
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 360\n",
    "BOX_COLOR = (255, 0, 0)\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "\n",
    "def visualize_bbox(img, bbox, class_id, class_idx_to_name, color=BOX_COLOR, thickness=2):\n",
    "    x_min, y_min, x_max, y_max = map(int, bbox)\n",
    "#     x_min, y_min, w, h = bbox\n",
    "#     x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    class_name = class_idx_to_name[class_id]\n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    cv2.putText(img, class_name, (x_min, y_min - int(0.3 * text_height)), cv2.FONT_HERSHEY_SIMPLEX, 0.35,TEXT_COLOR, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def visualize(annotations, category_id_to_name):\n",
    "    img = annotations['image'].copy()\n",
    "    for idx, bbox in enumerate(annotations['bboxes']):\n",
    "        img = visualize_bbox(img, bbox, annotations['category_id'][idx], category_id_to_name)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(img)\n",
    "    return img\n",
    "\n",
    "def get_aug(aug, min_area=0., min_visibility=0.):\n",
    "    return albumentations.Compose(aug, bbox_params={'format': 'pascal_voc', 'min_area': min_area, 'min_visibility': min_visibility, 'label_fields': ['category_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dbb13d-147b-4789-8d02-292a4cb8d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def j2anno(j):\n",
    "    # bbox coordinates are returned in pascal voc format [x_min, y_min, x_max, y_max]\n",
    "    im = cv2.imread(f\"train-object-detect\\\\{j['filename']}\", cv2.IMREAD_COLOR)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = cv2.resize(im, (360,360), interpolation = cv2.INTER_AREA)\n",
    "    im_height, im_width, _ = im.shape\n",
    "                    \n",
    "    orig_im = cv2.imread(f\"train-object-detect\\\\{j['filename']}\", cv2.IMREAD_COLOR)\n",
    "    orig_im_height, orig_im_width, _ = orig_im.shape\n",
    "\n",
    "    bbox_info = [anno for anno in j['annotations'] if anno['class'] == 'rect'][0]\n",
    "    orig_bbox = [np.clip(bbox_info['x'], 0, orig_im_width), np.clip(bbox_info['y'], 0, orig_im_height), np.clip(bbox_info['x']+bbox_info['width'], 0, orig_im_width), np.clip(bbox_info['y']+bbox_info['height'], 0, orig_im_height)]\n",
    "    bbox = [orig_bbox[0] * SZ / orig_im_width, orig_bbox[1] * SZ / orig_im_height, orig_bbox[2] * SZ / orig_im_width,  orig_bbox[3] * SZ / orig_im_height]\n",
    "    return {'image': im, 'bboxes': [bbox], 'category_id': [0]}\n",
    "                         \n",
    "cat2name = {0: 'rect'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74bff3-ac1e-4d3f-af35-255971530fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = np.stack([visualize(j2anno(j[i]), cat2name) for i in range(6)])\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.axis('off')\n",
    "plt.imshow(montage(np.stack(ims), multichannel=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
